"""Base class for generating OPDS feeds."""
# Standard library imports
from base64 import b64encode
from copy import deepcopy
from datetime import datetime

# Third-party imports
from lxml import etree
from fastapi.responses import Response

# Local application imports
from opds_abs.config import AUDIOBOOKSHELF_API
from opds_abs.utils import dict_to_xml
from opds_abs.utils.error_utils import FeedGenerationError, log_error

class BaseFeedGenerator:
    """Base class for creating OPDS feed components.

    This class provides the foundation for generating OPDS (Open Publication Distribution System)
    feeds for Audiobookshelf content. It includes methods for creating feed structures,
    adding book entries, filtering content, and generating responses.

    Architecture Overview:
    ---------------------
    The OPDS-ABS application uses a hierarchical feed generation system where this base class
    provides common functionality, and specialized subclasses implement specific feed types:

    - LibraryFeedGenerator: Root feed and library items feeds
    - NavigationFeedGenerator: Navigation feeds for different content views
    - SeriesFeedGenerator: Series lists and series item feeds
    - AuthorFeedGenerator: Author listings and author-specific item feeds
    - CollectionFeedGenerator: Collection listings and collection-specific item feeds
    - SearchFeedGenerator: Search results feeds

    Each specialized generator builds on the base functionality to create OPDS-compliant
    XML feeds for different sections of the application. The system is designed to be
    extensible, allowing new feed types to be added easily.

    Components Interaction:
    ---------------------
    1. Feed generators are instantiated in the main.py FastAPI application
    2. Route handlers call specific generator methods based on the requested endpoint
    3. Generators fetch data using the API client and cache mechanisms
    4. XML feeds are built using the helper methods in this base class
    5. Responses are returned to the client in OPDS-compliant format
    """

    def __init__(self):
        """Initialize a new BaseFeedGenerator instance.

        Creates an empty base feed with the appropriate XML namespace declarations
        for OPDS (Open Publication Distribution System) and Atom feeds. This base feed
        serves as the foundation for all feed types generated by derived classes.

        The initialized feed includes:
        - xmlns="http://www.w3.org/2005/Atom" namespace
        - opds="http://opds-spec.org/2010/catalog" namespace mapping
        - opensearch="http://a9.com/-/spec/opensearch/1.1/" namespace mapping for pagination
        """
        self.base_feed = etree.Element(
            "feed",
            xmlns="http://www.w3.org/2005/Atom",
            nsmap={
                "opds": "http://opds-spec.org/2010/catalog",
                "opensearch": "http://a9.com/-/spec/opensearch/1.1/"
            }
        )

    def create_base_feed(self, username=None, library_id=None, current_path=None, token=None):
        """Create a copy of the base feed with optional search link.

        Args:
            username (str, optional): Username for personalized feed. Defaults to None.
            library_id (str, optional): Library ID to associate with the feed. Defaults to None.
            current_path (str, optional): Current path for pagination links. Defaults to None.

        Returns:
            Element: An lxml Element object representing the base feed structure.
        """
        base_feed = deepcopy(self.base_feed)

        # Add updated timestamp to the feed
        updated_el = etree.SubElement(base_feed, "updated")
        updated_el.text = self.get_current_timestamp()

        if username and library_id:
            search_link = {
                "link": {
                    "_attrs": {
                        "href": f"/opds/{username}/libraries/{library_id}/search.xml",
                        "rel": "search",
                        "type": "application/opensearchdescription+xml"
                    }
                }
            }
            dict_to_xml(base_feed, search_link)

            if current_path:
                # Base URL parameters
                # Check if current_path already has parameters
                separator = "&" if "?" in current_path else "?"
                auth_param = f"{separator}token={token}" if token else ""

                # Add start link
                start_link = {
                    "link": {
                        "_attrs": {
                            "rel": "start",
                            "title": "Start Page",
                            "type": "application/atom+xml;profile=opds-catalog",
                            "href": f"/opds/{username}/libraries/{library_id}{auth_param}"
                        }
                    }
                }
                dict_to_xml(base_feed, start_link)

                # Add self link
                self_link = {
                    "link": {
                        "_attrs": {
                            "rel": "self",
                            "title": "This Page",
                            "type": "application/atom+xml;profile=opds-catalog",
                            "href": f"/opds/{current_path}{auth_param}"
                        }
                    }
                }
                dict_to_xml(base_feed, self_link)

                # Add HTML alternate link
                alternate_link = {
                    "link": {
                        "_attrs": {
                            "rel": "alternate",
                            "title": "HTML Page",
                            "type": "text/html",
                            "href": f"/opds/{current_path}{auth_param}"
                        }
                    }
                }
                dict_to_xml(base_feed, alternate_link)

        return base_feed

    def create_response(self, feed):
        """Convert feed to XML and create a response.

        Args:
            feed (Element): The lxml Element containing the complete feed.

        Returns:
            Response: A FastAPI Response object with the XML content.
        """
        try:
            feed_xml = etree.tostring(
                    feed,
                    pretty_print=True,
                    xml_declaration=False,
                    encoding="UTF-8"
            )
            return Response(content=feed_xml, media_type="application/atom+xml")
        except Exception as e:
            log_error(e, context="Creating XML response")
            raise FeedGenerationError("Failed to generate XML response") from e

    def add_book_to_feed(self, feed, book, ebook_inos, query_filter="", token=None):
        """Add a book to the feed with all its metadata.

        This method creates an OPDS entry for a book in the feed, including its metadata,
        download links, and cover image. It handles various book formats and ensures
        proper linking with authentication tokens when required.

        Args:
            feed (Element): The lxml Element to add the book entry to.
            book (dict): Dictionary containing book data from Audiobookshelf API.
            ebook_inos (list): List of ebook identifier objects containing ino numbers.
            query_filter (str, optional): Filter string to customize the entry. Defaults to "".
            token (str, optional): Authentication token to use for download links.

        Raises:
            FeedGenerationError: If there's an error adding the book to the feed.
        """
        import logging
        logger = logging.getLogger(__name__)

        try:
            book_id = book.get("id", "")
            media = book.get("media", {})
            book_metadata = media.get("metadata", {})
            book_title = book_metadata.get("title", "Unknown Title")
            book_author = book_metadata.get("authorName", "Unknown Author")

            # Check if the token was provided in the method call
            # If not, try to get it from the ebook_inos object
            effective_token = token
            if not effective_token and ebook_inos and len(ebook_inos) > 0:
                # Try to get the token from the first ebook file
                effective_token = ebook_inos[0].get('token')
                if effective_token:
                    logger.debug("Using token from ebook file for book '%s'", book_title)

            # Log detailed information about the book and token
            logger.debug("Adding book to feed: '%s' (ID: %s), token present: %s", book_title, book_id, effective_token is not None)

            # Extract ebook format - check both direct and nested paths (for search results)
            ebook_format = media.get("ebookFormat", media.get("ebookFile", {}).get("ebookFormat"))
            logger.debug("Book '%s' format: %s", book_title, ebook_format)

            for ebook in ebook_inos:
                book_path = f"{AUDIOBOOKSHELF_API}/items/{book_id}"
                file_ino = ebook.get('ino')

                # Use our proxy endpoint instead of direct Audiobookshelf API link
                # No need to append token as query parameter since our proxy handles authentication
                download_path = f"/opds/proxy/download/{book_id}/file/{file_ino}"
                logger.debug("Generated proxied download URL for '%s': %s", book_title, download_path)

                # Cover URL doesn't need authentication
                cover_url = f"{book_path}/cover?format=jpeg"
                series_list = book_metadata.get("seriesName", None)
                added_at = datetime.fromtimestamp(book.get('addedAt')/1000).strftime('%Y-%m-%d')

                # Create the description content with HTML formatting
                content_text = (
                    f"{book_metadata.get('description', '')}<br/><br/>"
                    f"{'Series: ' + series_list + '<br/>' if series_list else ''}"
                    f"Published year: {book_metadata.get('publishedYear')}<br/>"
                    f"Genres: {', '.join(book_metadata.get('genres', []))}<br/>"
                    f"Added at: {added_at}<br/>"
                )

                if ebook_format == "pdf":
                    ebook_link_type = ebook_format
                else:
                    ebook_link_type = f"{ebook_format}+zip"

                # Build the entry data structure
                entry_data = {
                    "entry": {
                        "title": {"_text": book_title},
                        "id": {"_text": book_id},
                        "updated": {"_text": self.get_current_timestamp()},
                        "content": {
                            "_attrs": {"type": "xhtml"},
                            "_text": content_text
                        },
                        "author": {
                            "name": {"_text": book_author}
                        },
                        "link": [
                            {
                                "_attrs": {
                                    "href": download_path,
                                    "rel": "http://opds-spec.org/acquisition",
                                    "type": f"application/{ebook_link_type}",
                                    "title": f"{book_author} - {book_title}"
                                }
                            },
                            {
                                "_attrs": {
                                    "href": cover_url,
                                    "rel": "http://opds-spec.org/image",
                                    "type": "image/jpeg"
                                }
                            }
                        ]
                    }
                }

                # Add series info if filtering by series
                if query_filter.startswith("series"):
                    series_number = book_metadata.get('series', {}).get("sequence", "")
                    series_name = book_metadata.get('series', {}).get("name", "")
                    entry_data["entry"]["series"] = {
                        "name": {"_text": f" - {series_name} #{series_number}"}
                    }

                # Convert the dictionary to XML elements
                dict_to_xml(feed, entry_data)

        except (ValueError, KeyError) as e:
            book_title = book.get("media", {}).get("metadata", {}).get("title", "Unknown")
            context = f"Adding book '{book_title}' to feed"
            log_error(e, context=context)
            raise FeedGenerationError(f"Failed to add book to feed: {str(e)}") from e
        except Exception as e:
            book_title = book.get("media", {}).get("metadata", {}).get("title", "Unknown")
            context = f"Adding book '{book_title}' to feed"
            log_error(e, context=context)
            raise FeedGenerationError(f"Unexpected error adding book to feed: {str(e)}") from e

    def create_filter(self, abs_filter=None):
        """Create a base64-encoded filter to be used by Audiobookshelf.

        Args:
            abs_filter (str, optional): Filter string to encode. Defaults to None.

        Returns:
            str: Base64-encoded filter string.
        """
        try:
            if abs_filter is None:
                return ""
            return b64encode(abs_filter.encode("utf-8")).decode("utf-8")
        except Exception as e:
            log_error(e, context="Creating base64 filter")
            # Return empty string on error rather than raising exception
            # since this is a utility function
            return ""

    def filter_items(self, data):
        """Find items in a library that have an ebook file, sorted by a field in a specific order.

        Args:
            data (dict): The data containing items to filter.

        Returns:
            list: Filtered list of items that have ebook files.

        Raises:
            FeedGenerationError: If there's an error filtering the items.
        """
        try:
            n = 1
            filtered_results = []
            for result in data.get("results", []):
                media = result.get("media", {})
                if "ebookFormat" in media and media.get("ebookFormat", None):
                    result.update({"opds_seq":n})
                    n += 1
                    filtered_results.append(result)

            return filtered_results
        except Exception as e:
            log_error(e, context="Filtering items for ebooks")
            raise FeedGenerationError(f"Error filtering items: {str(e)}") from e

    def sort_results(self, data):
        """Sort results based on the opds_seq field.

        Args:
            data (list): List of items to sort.

        Returns:
            list: Sorted list of items.

        Raises:
            FeedGenerationError: If there's an error sorting the results.
        """
        try:
            sorted_results = sorted(
                    data,
                    key=lambda x: x["opds_seq"],
                    reverse=False
                )
            return sorted_results
        except Exception as e:
            log_error(e, context="Sorting results")
            raise FeedGenerationError(f"Error sorting results: {str(e)}") from e

    def extract_value(self, item, path):
        """Extract value from a nested dictionary using a dot-separated path.

        Args:
            item (dict): The dictionary to extract values from.
            path (str): Dot-separated path indicating where to find the value.

        Returns:
            any: The extracted value, or None if the path doesn't exist.
        """
        try:
            keys = path.split('.')
            for key in keys:
                item = item.get(key, None)
                if item is None:
                    break
            return item
        except Exception as e:
            # Just log here but don't raise as this is a utility function
            log_error(e, context=f"Extracting value from path {path}")
            return None

    def add_pagination_metadata(self, feed, page, items_per_page, total_items):
        """Add OpenSearch pagination metadata elements to the feed.

        Args:
            feed (Element): The XML feed to add pagination metadata to
            page (int): Current page number (1-based)
            items_per_page (int): Number of items per page
            total_items (int): Total number of items across all pages
        """
        start_index = (page - 1) * items_per_page + 1  # OpenSearch is 1-indexed

        # Add opensearch elements
        items_per_page_el = etree.SubElement(feed, "{http://a9.com/-/spec/opensearch/1.1/}itemsPerPage")
        items_per_page_el.text = str(items_per_page)

        start_index_el = etree.SubElement(feed, "{http://a9.com/-/spec/opensearch/1.1/}startIndex")
        start_index_el.text = str(start_index)

        total_results_el = etree.SubElement(feed, "{http://a9.com/-/spec/opensearch/1.1/}totalResults")
        total_results_el.text = str(total_items)

    def add_pagination_links(self, feed, current_path, page, items_per_page, total_items, token=None):
        """Add next/previous pagination links to the feed.

        Args:
            feed (Element): The XML feed to add pagination links to
            current_path (str): Current path excluding query parameters
            page (int): Current page number (1-based)
            items_per_page (int): Number of items per page
            total_items (int): Total number of items
            token (str, optional): Authentication token
        """
        total_pages = (total_items + items_per_page - 1) // items_per_page  # Ceiling division

        # Base URL parameters
        auth_param = f"&token={token}" if token else ""

        # Check if current_path already has parameters
        has_params = "?" in current_path

        # Add next page link if there are more pages
        if page < total_pages:
            next_page = page + 1
            next_start_index = (next_page - 1) * items_per_page + 1

            # Use correct separator based on existing parameters
            separator = "&" if has_params else "?"

            next_link = {
                "link": {
                    "_attrs": {
                        "rel": "next",
                        "title": "Next Page",
                        "type": "application/atom+xml;profile=opds-catalog",
                        "href": f"/opds/{current_path}{separator}start_index={next_start_index}{auth_param}"
                    }
                }
            }
            dict_to_xml(feed, next_link)

        # Add previous page link if not on first page
        if page > 1:
            prev_page = page - 1
            prev_start_index = (prev_page - 1) * items_per_page + 1

            # Use correct separator based on existing parameters
            separator = "&" if has_params else "?"

            prev_link = {
                "link": {
                    "_attrs": {
                        "rel": "previous",
                        "title": "Previous Page",
                        "type": "application/atom+xml;profile=opds-catalog",
                        "href": f"/opds/{current_path}{separator}start_index={prev_start_index}{auth_param}"
                    }
                }
            }
            dict_to_xml(feed, prev_link)

    def paginate_results(self, items, start_index, items_per_page):
        """Paginate results based on the start index and items per page.

        Args:
            items (list): List of items to paginate
            start_index (int): 1-based start index (will be converted to 0-based for slicing)
            items_per_page (int): Number of items per page, 0 means show all items

        Returns:
            list: Paginated list of items
        """
        if not items:
            return []

        # If items_per_page is 0, return all items (no pagination)
        if items_per_page <= 0:
            return items

        # Convert 1-based OpenSearch index to 0-based Python index
        start_idx = start_index - 1 if start_index > 0 else 0

        # Ensure start_idx is within range
        if start_idx >= len(items):
            start_idx = 0

        end_idx = start_idx + items_per_page

        return items[start_idx:end_idx]

    def get_current_timestamp(self):
        """Get the current timestamp in ISO 8601 format.

        Returns:
            str: Current timestamp in ISO 8601 format (e.g. 2025-04-21T12:34:56Z)
        """
        return datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')
